{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3GaQtk2XoXOZsljTdWVpf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Long3309/CS221-Project/blob/main/Project_CS221.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Tải thư viện\n"
      ],
      "metadata": {
        "id": "83pjlVfa801O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QNgGF4Z48thx"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import unicodedata as ud\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import ast\n",
        "import re\n",
        "import nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
        "warnings.filterwarnings(action='ignore', category=FutureWarning)"
      ],
      "metadata": {
        "id": "nJA4YdaH88sD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load dữ liệu"
      ],
      "metadata": {
        "id": "1CgyyJ1N9NTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/Long3309/CS221-Project/main/dataset/sentences.txt\""
      ],
      "metadata": {
        "id": "0URp3cnG9VAm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Long3309/CS221-Project.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kuie3GIc_SM4",
        "outputId": "c67782af-fab7-4579-c823-5249705e12ee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'CS221-Project' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls CS221-Project/dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHhmQszo_4pq",
        "outputId": "67c90144-1be6-46bd-b910-774d6b9cc4de"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gold.txt       test_gold.txt   train_gold.txt\n",
            "sentences.txt  test_words.txt  train_words.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = open('CS221-Project/dataset/sentences.txt', encoding='utf-8').readlines()\n",
        "tokenize_sentences = [sentence.split(' ') for sentence in sentences]"
      ],
      "metadata": {
        "id": "n0I_31s6_fiC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Số lượng câu đã thu thập:', len(sentences))\n",
        "sentences[0:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hhf42w8Af22",
        "outputId": "62b6b861-2957-4f0a-baed-8707607497e2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Số lượng câu đã thu thập: 60\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Pha lập công trên đã giúp Rashford giải hạn bàn thắng tại sân Old Trafford kéo dài 845 phút .\\n',\n",
              " 'Với 3 điểm có được trong trận đấu này , Quỷ đỏ đã leo lên vị trí thứ 2 trên bảng xếp hạng Premier League với 30 điểm , chỉ kém đội đầu bảng Liverpool 2 điểm .\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_str = max(tokenize_sentences, key=len)\n",
        "print('Câu có số từ nhiều nhât:', len(max_str))\n",
        "' '.join(max_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "um-asjVSA_lv",
        "outputId": "a4e94686-c0ec-4bb3-9a8b-a59538249ca5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Câu có số từ nhiều nhât: 46\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Những thực phẩm được chế biến như hun khói , thức ăn ngâm tẩm , muối , món ăn chứa lượng muối cao thường có tỷ lệ mắc ung thư dạ dày cao hơn những người có thói quen ăn uống nhạt và thanh đạm .\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_str = min(tokenize_sentences, key=len)\n",
        "print('Câu có số từ ít nhât:', len(min_str))\n",
        "' '.join(min_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "8KW8xQuvBBqJ",
        "outputId": "0a217a72-a9ff-49cf-bacb-a68d619f7fc2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Câu có số từ ít nhât: 8\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Nhiều người có hoàn cảnh giống ông .\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Tách từ\n"
      ],
      "metadata": {
        "id": "PQkDRLoeBGDj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Sử dụng thuật toán Longest-Matching"
      ],
      "metadata": {
        "id": "PPpHKKB4B7ex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def syllablize(sentence):\n",
        "    word = '\\w+'\n",
        "    non_word = '[^\\w\\s]'\n",
        "    digits = '\\d+([\\.,_]\\d+)+'\n",
        "    \n",
        "    patterns = []\n",
        "    patterns.extend([word, non_word, digits])\n",
        "    patterns = f\"({'|'.join(patterns)})\"\n",
        "    \n",
        "    sentence = ud.normalize('NFC', sentence)\n",
        "    tokens = re.findall(patterns, sentence, re.UNICODE)\n",
        "    return [token[0] for token in tokens]"
      ],
      "metadata": {
        "id": "c3Mx--iZBKAC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_n_grams(path):\n",
        "    with open(path, encoding='utf8') as f:\n",
        "        words = f.read()\n",
        "        words = ast.literal_eval(words)\n",
        "    return words"
      ],
      "metadata": {
        "id": "Mf2Ni0kzBL1T"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def longest_matching(sentence, bi_grams, tri_grams):\n",
        "    syllables = syllablize(sentence)\n",
        "    syl_len = len(syllables)\n",
        "    \n",
        "    curr_id = 0\n",
        "    word_list = []\n",
        "    done = False\n",
        "    \n",
        "    while (curr_id < syl_len) and (not done):\n",
        "        curr_word = syllables[curr_id]\n",
        "        if curr_id >= syl_len - 1:\n",
        "            word_list.append(curr_word)\n",
        "            done = True\n",
        "        else:\n",
        "            next_word = syllables[curr_id + 1]\n",
        "            pair_word = ' '.join([curr_word.lower(), next_word.lower()])\n",
        "            if curr_id >= (syl_len - 2):\n",
        "                if pair_word in bi_grams:\n",
        "                    word_list.append('_'.join([curr_word, next_word]))\n",
        "                    curr_id += 2\n",
        "                else:\n",
        "                    word_list.append(curr_word)\n",
        "                    curr_id += 1\n",
        "            else:\n",
        "                next_next_word = syllables[curr_id + 2]\n",
        "                triple_word = ' '.join([pair_word, next_next_word.lower()])\n",
        "                if triple_word in tri_grams:\n",
        "                    word_list.append('_'.join([curr_word, next_word, next_next_word]))\n",
        "                    curr_id += 3\n",
        "                elif pair_word in bi_grams:\n",
        "                    word_list.append('_'.join([curr_word, next_word]))\n",
        "                    curr_id += 2\n",
        "                else:\n",
        "                    word_list.append(curr_word)\n",
        "                    curr_id += 1\n",
        "    return word_list"
      ],
      "metadata": {
        "id": "mAxn1ZqWBM3V"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bi_grams = load_n_grams('CS221-Project/resources/bi_grams.txt')\n",
        "tri_grams = load_n_grams('CS221-Project/resources/tri_grams.txt')\n",
        "longest_matching('nhưng sự thực hiện vẫn còn chưa phù hợp', bi_grams, tri_grams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WE_Ukk8gCFmZ",
        "outputId": "58fac670-21b3-45b9-cdd2-65b95db2bd14"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nhưng', 'sự_thực', 'hiện', 'vẫn', 'còn', 'chưa', 'phù_hợp']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('CS221-Project/tokenize/longest_matching_tokens.txt', 'w', encoding='utf-8') as f:\n",
        "    longest_matching_sentences = []\n",
        "    for sentence in sentences:\n",
        "        word_list = longest_matching(sentence, bi_grams, tri_grams)\n",
        "        longest_matching_sentences.append(' '.join(word_list))\n",
        "        for word in word_list: f.write(word + '\\n')\n",
        "        if sentence != sentences[-1]: f.write('\\n')\n",
        "    f.write('\\n')\n",
        "longest_matching_sentences[0:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETTEN7c-COmL",
        "outputId": "5d206155-b57a-4c93-fb92-2709ea1f5dd2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Pha lập_công trên đã giúp Rashford giải hạn bàn thắng tại sân Old Trafford kéo dài 845 phút .',\n",
              " 'Với 3 điểm có được trong trận đấu này , Quỷ đỏ đã leo lên vị_trí thứ 2 trên bảng xếp_hạng Premier League với 30 điểm , chỉ kém đội đầu_bảng Liverpool 2 điểm .',\n",
              " 'Tổng_thống đắc_cử Joe Biden được cho đang cân_nhắc việc cắt bỏ chương_trình hiện_đại hóa hạt_nhân trị_giá 1 . 000 tỷ USD do chính_quyền Tổng_thống đương_nhiệm Donald Trump đề_xuất .']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_longest_matching_compounds = 0\n",
        "for sentence in longest_matching_sentences:\n",
        "    for word in sentence.split():\n",
        "        if '_' in word: count_longest_matching_compounds += 1\n",
        "print('Số lượng từ ghép khi tách từ bằng thuật toán Longest Matching:', count_longest_matching_compounds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNEL_ISVCcUg",
        "outputId": "97fbb3ac-aef9-47b5-b500-0b20aac17b65"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Số lượng từ ghép khi tách từ bằng thuật toán Longest Matching: 257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Sử dụng thư viện VNCoreNLP\n",
        "\n",
        "\n",
        "1.   Cài đặt py-vncorenlp\n",
        "2.   Khởi tạo đối tượng VNCoreNLP\n",
        "3.   Xử lý đối tượng VNCoreNLP\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HUWLeCkaCeCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install py-vncorenlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dtb6NRXCDif-",
        "outputId": "303276c7-8da8-4478-e0e6-ec1d3c032f56"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: py-vncorenlp in /usr/local/lib/python3.7/dist-packages (0.1.3)\n",
            "Requirement already satisfied: pyjnius in /usr/local/lib/python3.7/dist-packages (from py-vncorenlp) (1.4.2)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from pyjnius->py-vncorenlp) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import py_vncorenlp\n",
        "py_vncorenlp.download_model(save_dir='./')\n",
        "model = py_vncorenlp.VnCoreNLP(annotators=[\"wseg\", \"pos\", \"ner\", \"parse\"], save_dir='./')"
      ],
      "metadata": {
        "id": "KvcGOcU3Dl_0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vncore_tokenize(sentence):\n",
        "  vncore_sentences = model.annotate_text(sentence)\n",
        "  sent = vncore_sentences[0]\n",
        "  word_list = []\n",
        "  for word in sent:\n",
        "    word_list.append(word[\"wordForm\"])\n",
        "  return word_list"
      ],
      "metadata": {
        "id": "RGaxWpGXUdhc"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vncore_tokenize(\"Số lượng từ ghép khi tách từ bằng thuật toán Longest Matching\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07NiCmq3j4p2",
        "outputId": "658d074f-6ae1-43ec-9706-f0c3b93b51c3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Số_lượng',\n",
              " 'từ',\n",
              " 'ghép',\n",
              " 'khi',\n",
              " 'tách',\n",
              " 'từ',\n",
              " 'bằng',\n",
              " 'thuật_toán',\n",
              " 'Longest_Matching']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('CS221-Project/tokenize/vncore_tokenss.txt', 'w', encoding='utf-8') as f:\n",
        "    vncore_sentences = []\n",
        "    for sentence in sentences:\n",
        "        word_list = vncore_tokenize(sentence)\n",
        "        vncore_sentences.append(' '.join(word_list))\n",
        "        for word in word_list: f.write(word + '\\n')\n",
        "        if sentence != sentences[-1]: f.write('\\n')\n",
        "    f.write('\\n')\n",
        "vncore_sentences[0:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHNHMyhOEE2y",
        "outputId": "60690748-0673-45eb-9fc0-02f97721f755"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Pha lập_công trên đã giúp Rashford giải hạn bàn thắng tại sân Old_Trafford kéo_dài 845 phút .',\n",
              " 'Với 3 điểm có được trong trận đấu này , Quỷ đỏ đã leo lên vị_trí thứ 2 trên bảng xếp_hạng Premier_League với 30 điểm , chỉ kém đội đầu_bảng Liverpool 2 điểm .',\n",
              " 'Tổng_thống đắc_cử Joe_Biden được cho đang cân_nhắc việc cắt bỏ chương_trình hiện_đại_hoá hạt_nhân trị_giá 1.000 tỷ USD do chính_quyền Tổng_thống đương_nhiệm Donald_Trump đề_xuất .']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ]
}